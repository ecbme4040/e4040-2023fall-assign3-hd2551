{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columbia University\n",
    "### ECBM E4040 Neural Networks and Deep Learning. Fall 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJCMCx6ISZZw"
   },
   "source": [
    "## **Task 2: RNN Application -- Tweet Sentiment Analysis** (25%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8wjQhNtSffW"
   },
   "source": [
    "In this task, you are going to classify the sentiment of tweets based on whether they are positive or negative using an LSTM model. The code to load the data and see its characteristics has been provided to you. \n",
    "\n",
    "In the first task, you will encode the data using one-hot encoding and train an LSTM network to classify the sentiment. In the second task, you will replace the one hot encoding with an embedding layer and train another LSTM model. You will then extract the trained embeddings and visualize the word embeddings in 2 dimensions by using TSNE for dimensionality reduction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UZ_G4XdfP7GK"
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MjTYqMoN8fh"
   },
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F55EwI6RQl1A",
    "outputId": "1e087591-3dad-4471-97df-d9af9214dddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of original train set: 60000\n",
      "size of original test set: 20000\n",
      "****************************************************************************************************\n",
      "size of train set: 60000, #positive: 30055, #negative: 29945\n",
      "size of test set: 1000, #positive: 510, #negative: 490\n",
      "['it', 'will', 'help', 'relieve', 'your', 'stress', 'padtoken', 'padtoken', 'padtoken', 'padtoken', 'padtoken', 'padtoken', 'padtoken', 'padtoken', 'padtoken', 'padtoken', 'padtoken', 'padtoken', 'padtoken', 'padtoken']\n",
      "sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "with open(\"./tweets_data/vocabulary.pkl\", \"rb\") as f:\n",
    "    vocabulary = pickle.load(f)\n",
    "\n",
    "# load our data and separate it into tweets and labels\n",
    "train_data = json.load(open('tweets_data/trainTweets_preprocessed.json', 'r'))\n",
    "train_data = list(map(lambda row:(np.array(row[0],dtype=np.int32),str(row[1])),train_data))\n",
    "train_tweets = np.array([t[0] for t in train_data])\n",
    "train_labels = np.array([int(t[1]) for t in train_data])\n",
    "\n",
    "test_data = json.load(open('tweets_data/testTweets_preprocessed.json', 'r'))\n",
    "test_data = list(map(lambda row:(np.array(row[0],dtype=np.int32),str(row[1])),test_data))\n",
    "test_tweets = np.array([t[0] for t in test_data])\n",
    "test_labels = np.array([int(t[1]) for t in test_data])\n",
    "\n",
    "print(\"size of original train set: {}\".format(len(train_tweets)))\n",
    "print(\"size of original test set: {}\".format(len(test_tweets)))\n",
    "\n",
    "# Only select the first 1000 test samples for testing\n",
    "test_tweets = test_tweets[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "print(\"*\"*100)\n",
    "print(\"size of train set: {}, #positive: {}, #negative: {}\".format(len(train_tweets), np.sum(train_labels), len(train_tweets)-np.sum(train_labels)))\n",
    "print(\"size of test set: {}, #positive: {}, #negative: {}\".format(len(test_tweets), np.sum(test_labels), len(test_tweets)-np.sum(test_labels)))\n",
    "\n",
    "# Show the text of the idx-th train tweet\n",
    "# The 'padtoken' is used to ensure each tweet has the same length\n",
    "idx = 100\n",
    "train_text = [vocabulary[x] for x in train_tweets[idx]]\n",
    "print(train_text)\n",
    "sentiment_label = [\"negative\", \"positive\"]\n",
    "print(\"sentiment: {}\".format(sentiment_label[train_labels[idx]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmjy9sPDOCnY"
   },
   "source": [
    "## Part 1 LSTM Encoder (5%)\n",
    "\n",
    "<font color=\"red\"><strong>TODO:</strong></font> Create and train a single-layer LSTM network to classify tweets.\n",
    "- Use one-hot encoding to represent each word in the tweet.\n",
    "- Set LSTM units to 128.\n",
    "- Use the Adam optimizer and set the batch size to 32.\n",
    "\n",
    "With these settings, what accuracy do you achieve? You can try to change some parameters in the network to see if you can improve the accuracy. \n",
    "\n",
    "<font color=\"red\"><strong>Hint:</strong></font> tf.one_hot and Keras functional API may be useful.\n",
    "<br>https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-Mx6WgMBVI3T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1518/1518 [==============================] - 37s 18ms/step - loss: 0.5813 - accuracy: 0.6806 - val_loss: 0.5044 - val_accuracy: 0.7602\n",
      "Epoch 2/10\n",
      "1518/1518 [==============================] - 26s 17ms/step - loss: 0.4651 - accuracy: 0.7832 - val_loss: 0.5051 - val_accuracy: 0.7515\n",
      "Epoch 3/10\n",
      "1518/1518 [==============================] - 26s 17ms/step - loss: 0.3885 - accuracy: 0.8317 - val_loss: 0.5869 - val_accuracy: 0.7236\n",
      "Epoch 4/10\n",
      "1518/1518 [==============================] - 26s 17ms/step - loss: 0.3201 - accuracy: 0.8681 - val_loss: 0.7235 - val_accuracy: 0.7349\n",
      "Epoch 5/10\n",
      "1518/1518 [==============================] - 27s 18ms/step - loss: 0.2743 - accuracy: 0.8882 - val_loss: 0.8710 - val_accuracy: 0.7329\n",
      "Epoch 6/10\n",
      "1518/1518 [==============================] - 26s 17ms/step - loss: 0.2495 - accuracy: 0.8990 - val_loss: 1.0009 - val_accuracy: 0.7100\n",
      "Epoch 7/10\n",
      "1518/1518 [==============================] - 26s 17ms/step - loss: 0.2331 - accuracy: 0.9053 - val_loss: 0.9726 - val_accuracy: 0.7258\n",
      "Epoch 8/10\n",
      "1518/1518 [==============================] - 28s 19ms/step - loss: 0.2263 - accuracy: 0.9054 - val_loss: 0.9766 - val_accuracy: 0.7247\n",
      "Epoch 9/10\n",
      "1518/1518 [==============================] - 27s 18ms/step - loss: 0.2098 - accuracy: 0.9129 - val_loss: 0.8917 - val_accuracy: 0.7212\n",
      "Epoch 10/10\n",
      "1518/1518 [==============================] - 26s 17ms/step - loss: 0.2017 - accuracy: 0.9152 - val_loss: 0.8960 - val_accuracy: 0.7303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0cd042f048>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "###################################################\n",
    "# TODO: Create a single-layer LSTM network.       #\n",
    "#                                                 #\n",
    "###################################################\n",
    "num_words = len(vocabulary)\n",
    "batch_size = 32\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_tweets, val_tweets, train_labels, val_labels = train_test_split(\n",
    "    train_tweets, train_labels, test_size=0.1, random_state=42)\n",
    "\n",
    "def one_hot_batch_generator(data, labels, batch_size, num_words):\n",
    "    while True:\n",
    "        for start in range(0, len(data), batch_size):\n",
    "            end = min(start + batch_size, len(data))\n",
    "            batch_data = data[start:end]\n",
    "            batch_labels = labels[start:end]\n",
    "\n",
    "            # One-hot encode the batch data\n",
    "            one_hot_data = tf.one_hot(batch_data, depth=num_words)\n",
    "\n",
    "            # Reshape the one-hot encoded data to 3D shape for LSTM\n",
    "            one_hot_data = tf.reshape(one_hot_data, (batch_data.shape[0], batch_data.shape[1], num_words))\n",
    "\n",
    "            yield one_hot_data, batch_labels\n",
    "\n",
    " # Create the training and validation generators\n",
    "train_generator = one_hot_batch_generator(train_tweets, train_labels, batch_size, num_words)\n",
    "val_generator = one_hot_batch_generator(val_tweets, val_labels, batch_size, num_words)\n",
    "\n",
    "# Calculate steps per epoch for training and validation\n",
    "train_steps_per_epoch = len(train_tweets) // batch_size\n",
    "val_steps = len(val_tweets) // batch_size\n",
    "\n",
    "# Assuming each tweet has a fixed length after padding\n",
    "tweet_length = train_tweets.shape[1]\n",
    "\n",
    "# Create the model\n",
    "input_layer = Input(shape=(tweet_length, num_words))\n",
    "lstm_layer = LSTM(128)(input_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(lstm_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch=train_steps_per_epoch, \n",
    "    epochs=10, \n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_steps\n",
    ")\n",
    "           \n",
    "###################################################\n",
    "# END TODO                                        #\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBiLRGc7RL-g"
   },
   "source": [
    "## Part 2: Embedding Lookup Layer (15%)\n",
    "\n",
    "### Define an Embedding Layer\n",
    "\n",
    "It's not hard to imagine that in the previous practices, the inputs we fed in were very sparse because each word was represented as a one-hot vector. This makes it difficult for the network to understand what story the input data is telling. A useful technique is *Word Embedding*.\n",
    "\n",
    "*Word Embedding*: Instead of using a one-hot vector to represent each word, we can add a word embedding matrix in which each word is represented as a low-dimensional vector. Note that this representation is not sparse anymore, because we're working in a continuous vector space now. Words that share similar/related semantic meanings should be 'close to each other' in this vector space (we could define a distance measure to estimate the closeness).\n",
    "\n",
    "<font color=\"red\"><strong>TODO:</strong></font> Define a similar model as above with some improvements.\n",
    "- Use an Embedding layer instead of one-hot embedding.\n",
    "- Run the provided training loop.\n",
    "- Report loss and accuracy for training and validation after each epoch.\n",
    "- Display the loss value after every 500 steps. \n",
    "\n",
    "Do you see any difference in accuracy? What about training time? What inference can you draw?\n",
    "\n",
    "**Hints**: Refer to the link below.\n",
    "<br>https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "x2mkQlVMVUny"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   1/1367 [..............................] - ETA: 32:29 - loss: 0.6945 - accuracy: 0.3125Batch 0: Loss = 0.6945074796676636\n",
      " 499/1367 [=========>....................] - ETA: 9s - loss: 0.6263 - accuracy: 0.6218Batch 500: Loss = 0.5775970816612244\n",
      " 996/1367 [====================>.........] - ETA: 3s - loss: 0.5923 - accuracy: 0.6651Batch 1000: Loss = 0.5455424189567566\n",
      "1367/1367 [==============================] - 16s 11ms/step - loss: 0.5783 - accuracy: 0.6813 - val_loss: 0.4974 - val_accuracy: 0.7691\n",
      "Epoch 2/10\n",
      "   1/1367 [..............................] - ETA: 14s - loss: 0.5435 - accuracy: 0.7500Batch 0: Loss = 0.5434795022010803\n",
      " 498/1367 [=========>....................] - ETA: 9s - loss: 0.4599 - accuracy: 0.7873Batch 500: Loss = 0.45215559005737305\n",
      "1000/1367 [====================>.........] - ETA: 3s - loss: 0.4559 - accuracy: 0.7888Batch 1000: Loss = 0.4544071853160858\n",
      "1367/1367 [==============================] - 15s 11ms/step - loss: 0.4563 - accuracy: 0.7885 - val_loss: 0.5035 - val_accuracy: 0.7693\n",
      "Epoch 3/10\n",
      "   1/1367 [..............................] - ETA: 15s - loss: 0.6305 - accuracy: 0.6250Batch 0: Loss = 0.6304754018783569\n",
      " 501/1367 [=========>....................] - ETA: 8s - loss: 0.4048 - accuracy: 0.8166Batch 500: Loss = 0.4096689224243164\n",
      " 997/1367 [====================>.........] - ETA: 3s - loss: 0.4101 - accuracy: 0.8132Batch 1000: Loss = 0.4182005822658539\n",
      "1367/1367 [==============================] - 14s 10ms/step - loss: 0.4128 - accuracy: 0.8120 - val_loss: 0.4924 - val_accuracy: 0.7658\n",
      "Epoch 4/10\n",
      "   1/1367 [..............................] - ETA: 17s - loss: 0.3858 - accuracy: 0.8750Batch 0: Loss = 0.38580581545829773\n",
      " 498/1367 [=========>....................] - ETA: 9s - loss: 0.3672 - accuracy: 0.8392Batch 500: Loss = 0.3719407320022583\n",
      " 997/1367 [====================>.........] - ETA: 3s - loss: 0.3724 - accuracy: 0.8350Batch 1000: Loss = 0.3828483819961548\n",
      "1367/1367 [==============================] - 15s 11ms/step - loss: 0.3756 - accuracy: 0.8326 - val_loss: 0.5424 - val_accuracy: 0.7580\n",
      "Epoch 5/10\n",
      "   1/1367 [..............................] - ETA: 14s - loss: 0.2233 - accuracy: 0.9062Batch 0: Loss = 0.22334106266498566\n",
      " 501/1367 [=========>....................] - ETA: 8s - loss: 0.3215 - accuracy: 0.8620Batch 500: Loss = 0.3287355899810791\n",
      "1001/1367 [====================>.........] - ETA: 3s - loss: 0.3294 - accuracy: 0.8567Batch 1000: Loss = 0.34280645847320557\n",
      "1367/1367 [==============================] - 15s 11ms/step - loss: 0.3334 - accuracy: 0.8535 - val_loss: 0.5869 - val_accuracy: 0.7502\n",
      "Epoch 6/10\n",
      "   1/1367 [..............................] - ETA: 15s - loss: 0.5106 - accuracy: 0.7500Batch 0: Loss = 0.5105534791946411\n",
      " 501/1367 [=========>....................] - ETA: 9s - loss: 0.2792 - accuracy: 0.8777Batch 500: Loss = 0.2889629006385803\n",
      " 999/1367 [====================>.........] - ETA: 3s - loss: 0.2885 - accuracy: 0.8723Batch 1000: Loss = 0.302691787481308\n",
      "1367/1367 [==============================] - 15s 11ms/step - loss: 0.2933 - accuracy: 0.8694 - val_loss: 0.6356 - val_accuracy: 0.7494\n",
      "Epoch 7/10\n",
      "   1/1367 [..............................] - ETA: 15s - loss: 0.3180 - accuracy: 0.8438Batch 0: Loss = 0.3180375099182129\n",
      " 501/1367 [=========>....................] - ETA: 8s - loss: 0.2646 - accuracy: 0.8813Batch 500: Loss = 0.26325809955596924\n",
      " 999/1367 [====================>.........] - ETA: 3s - loss: 0.2665 - accuracy: 0.8797Batch 1000: Loss = 0.2739267945289612\n",
      "1367/1367 [==============================] - 15s 11ms/step - loss: 0.2691 - accuracy: 0.8783 - val_loss: 0.7639 - val_accuracy: 0.7405\n",
      "Epoch 8/10\n",
      "   1/1367 [..............................] - ETA: 15s - loss: 0.1635 - accuracy: 0.9375Batch 0: Loss = 0.16354303061962128\n",
      " 499/1367 [=========>....................] - ETA: 8s - loss: 0.2262 - accuracy: 0.8993Batch 500: Loss = 0.23009178042411804\n",
      "1000/1367 [====================>.........] - ETA: 3s - loss: 0.2304 - accuracy: 0.8973Batch 1000: Loss = 0.23891955614089966\n",
      "1367/1367 [==============================] - 15s 11ms/step - loss: 0.2335 - accuracy: 0.8956 - val_loss: 0.7973 - val_accuracy: 0.7389\n",
      "Epoch 9/10\n",
      "   1/1367 [..............................] - ETA: 15s - loss: 0.1399 - accuracy: 0.9688Batch 0: Loss = 0.139889195561409\n",
      " 499/1367 [=========>....................] - ETA: 8s - loss: 0.1996 - accuracy: 0.9114Batch 500: Loss = 0.20376157760620117\n",
      " 998/1367 [====================>.........] - ETA: 3s - loss: 0.2034 - accuracy: 0.9087Batch 1000: Loss = 0.2091190665960312\n",
      "1367/1367 [==============================] - 15s 11ms/step - loss: 0.2060 - accuracy: 0.9073 - val_loss: 0.9305 - val_accuracy: 0.7305\n",
      "Epoch 10/10\n",
      "   1/1367 [..............................] - ETA: 14s - loss: 0.2021 - accuracy: 0.9062Batch 0: Loss = 0.20211225748062134\n",
      " 501/1367 [=========>....................] - ETA: 8s - loss: 0.1707 - accuracy: 0.9249Batch 500: Loss = 0.17924825847148895\n",
      " 997/1367 [====================>.........] - ETA: 3s - loss: 0.1772 - accuracy: 0.9212Batch 1000: Loss = 0.18844281136989594\n",
      "1367/1367 [==============================] - 15s 11ms/step - loss: 0.1815 - accuracy: 0.9189 - val_loss: 1.0153 - val_accuracy: 0.7325\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "###################################################\n",
    "# TODO: Create a single-layer LSTM network        #\n",
    "#       using Embedding layer                     #\n",
    "###################################################\n",
    "class DisplayLossCallback(Callback):\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if batch % 500 == 0:\n",
    "            print(f\"Batch {batch}: Loss = {logs['loss']}\")\n",
    "\n",
    "\n",
    "embedding_dim = 100  # Dimension of the embedding space\n",
    "\n",
    "input_layer = Input(shape=(None,))\n",
    "embedding_layer = Embedding(input_dim=num_words, output_dim=embedding_dim)(input_layer)\n",
    "lstm_layer = LSTM(128)(embedding_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(lstm_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_tweets, \n",
    "    train_labels, \n",
    "    batch_size=32, \n",
    "    epochs=10, \n",
    "    validation_split=0.1, \n",
    "    callbacks=[DisplayLossCallback()]\n",
    ")\n",
    "\n",
    "###################################################\n",
    "# END TODO                                        #\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cells to train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VyMFoLDYS82L"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_tweets, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "# Prepare the validation dataset.\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_tweets, test_labels))\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "train_acc_metric = keras.metrics.BinaryAccuracy() \n",
    "val_acc_metric = keras.metrics.BinaryAccuracy() \n",
    "\n",
    "train_loss_metric = keras.metrics.BinaryCrossentropy()\n",
    "val_loss_metric = keras.metrics.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDVUze74UUKO",
    "outputId": "15444b77-b341-4650-9bf9-88659141c83a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 0.2088\n",
      "Seen so far: 32 samples\n",
      "Training loss (for one batch) at step 500: 0.1810\n",
      "Seen so far: 16032 samples\n",
      "Training loss (for one batch) at step 1000: 0.2012\n",
      "Seen so far: 32032 samples\n",
      "Training loss (for one batch) at step 1500: 0.4805\n",
      "Seen so far: 48032 samples\n",
      "Training loss over epoch: 0.2220\n",
      "Training acc over epoch: 0.9013\n",
      "Validation loss: 0.5486\n",
      "Validation acc: 0.7500\n",
      "Time taken: 39.29s\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "import time\n",
    "optimizer = keras.optimizers.Adam() \n",
    "# Instantiate a loss function.\n",
    "loss_fn = keras.losses.BinaryCrossentropy()  \n",
    "\n",
    "\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    start_time = time.time()\n",
    "    epoch_loss= 0\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        # Update training metric.\n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "        train_loss_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "        epoch_loss+= float(loss_value)\n",
    "        # Log every 500 batches.\n",
    "        \n",
    "        if step % 500 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
    "        \n",
    "      \n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    train_loss = train_loss_metric.result()\n",
    "    print(\"Training loss over epoch: %.4f\" % (float(train_loss),))\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "    train_loss_metric.reset_states()\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for x_batch_val, y_batch_val in test_dataset:\n",
    "        val_logits = model(x_batch_val, training=False)\n",
    "        # Update val metrics\n",
    "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "        val_loss_metric.update_state(y_batch_val, val_logits)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    val_loss = val_loss_metric.result()\n",
    "    val_loss_metric.reset_states()\n",
    "\n",
    "    print(\"Validation loss: %.4f\" % (float(val_loss),))\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9WYOKJtUwe5"
   },
   "source": [
    "## Part 3: Visualize Word Vectors via t-SNE (5%)\n",
    "\n",
    "<font color=\"red\"><strong>TODO:</strong></font>\n",
    "- First, you need to retrieve the embedding matrix from the network.\n",
    "- Then use t-SNE to reduce each low-dimensional word vector into a 2D vector.\n",
    "- Then, you should visualize some interesting word pairs in 2D panel. (You may find scatter function in matplotlib.pyplot useful.)\n",
    "\n",
    "<font color=\"red\"><strong>Hint:</strong></font> You can use the t-SNE tool provided in scikit-learn, and if you encounter a dead kernel problem caused by \"Intel MKL FATAL ERROR: Cannot load libmkl_avx.so or libmkl_def.so\", please reinstall scikit-learn without MKL, ie., conda install nomkl numpy scipy scikit-learn numexpr.\n",
    "\n",
    "Here we provide some word pairs for you like indoor-outdoor activities and you can observe that these word-pair will look parallel with each other in a 2D t-SNE panel. You can find some other words and explore their relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/ecbm4040/envTF24/lib/python3.6/site-packages (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from scikit-learn) (1.19.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from scikit-learn) (1.5.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ecbm4040/envTF24/lib/python3.6/site-packages (from scikit-learn) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "aVZwhreIVlk0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Word pairs provided\n",
    "indoor_outdoor = ['reading', 'writing', 'hiking', 'camping']\n",
    "# You may try some other words as well\n",
    "\n",
    "###################################################\n",
    "# TODO: Visualize word vectors using TSNE.        #\n",
    "#                                                 #\n",
    "###################################################\n",
    "# Create a word-to-index mapping dictionary if 'vocabulary' represents words\n",
    "word_to_index = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "\n",
    "# Proceed with t-SNE visualization using the newly created mapping\n",
    "words = ['reading', 'writing', 'hiking', 'camping', 'dancing', 'fishing']\n",
    "word_indices = [word_to_index[word] for word in words if word in word_to_index]\n",
    "\n",
    "# Select the corresponding vectors from the embedding matrix\n",
    "selected_word_vectors = embedding_matrix[word_indices]\n",
    "\n",
    "# Use t-SNE for Dimensionality Reduction\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "word_vectors_2d = tsne.fit_transform(selected_word_vectors)\n",
    "\n",
    "# Visualize with Matplotlib\n",
    "plt.figure(figsize=(10, 10))\n",
    "for word, coord in zip(words, word_vectors_2d):\n",
    "    x, y = coord\n",
    "    plt.scatter(x, y, marker='x')\n",
    "    plt.text(x + 0.05, y + 0.05, word, fontsize=9)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "###################################################\n",
    "# END TODO                                        #\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"><strong>Note:</strong></font> Install **sklearn** if you haven't already. \n",
    "\n",
    "```\n",
    "> pip install scikit-learn\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Assignment_3_task_2_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "36142657f443a869bd2c1b509e6f1df9b014ad48aa206cdd00d27f8f22cb37ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
